{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                y  \n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()\n",
    "#Transform the data such that there are only 2 columns, 1 being X which is a 28*28 matrix and y which is the label\n",
    "cols = ['pixel'+str(i) for i in range(784)]\n",
    "train['X'] = train[cols].values.tolist()\n",
    "train.drop(cols,inplace = True,axis = 1)\n",
    " # Convert y into a format where is a vector where it is 1 for the correct number and 0 elsewhere\n",
    "train['y'] = train[\"label\"].apply(lambda x:[0 if i != x else 1 for i in range(10)])\n",
    "train.drop('label',inplace = True,axis = 1)\n",
    "train.head()\n",
    "# Alternatively this step may be skipped and is likely to be skipped when using traditional libraries such as TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x223ab1ff548>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(train.loc[9,\"X\"]).reshape(28,28),cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From scratch generation of a simple neural network where first layer is 784 neurons, 2nd layer is 25 neurons and last (output) layer is 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self,learning_rate = 0.001, epochs = 1000,batch = 10):\n",
    "        #Weights is a list of different matrix each the first layer corresponding to the first matrix\n",
    "        #Randomly Initialize weights\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.weights = [np.random.randn(784,25),np.random.randn(25,10)]\n",
    "        self.bias = [np.random.randn(25),np.random.randn(10)]\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    def sigmoid_deriv(self,z): # Will this work if I dont put in self IF i only call the method within the class?\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    def predict(self,X): #Perform the forward propagation step on 1 training example\n",
    "        l2 = np.dot(X,self.weights[0]) + self.bias[0]\n",
    "        l2_activ = self.sigmoid(l2)\n",
    "        l3 = np.dot(l2_activ,self.weights[1]) + self.bias[1]\n",
    "        pred = self.sigmoid(l3)\n",
    "        return [np.argmax(i) for i in pred]\n",
    "    def learn(self,X,y): #Simple Learning Step using Batch Gradient Descent - Really hope my computer can survive this\n",
    "        for epoch in range(self.epochs):\n",
    "            db,dw = self.backprop(X,y)\n",
    "            for i in range(2):\n",
    "                self.weights[i] -= dw[i]*self.learning_rate\n",
    "                self.bias[i] -=  sum(db[i])*self.learning_rate\n",
    "            if not epoch % 10 :\n",
    "                print(\"Epoch\", epoch,\"with a cost of \",self.cost(X,y))\n",
    "                \n",
    "    def cost(self,X,y):\n",
    "        l2 = np.dot(X,self.weights[0]) + self.bias[0]\n",
    "        l2_activ = self.sigmoid(l2)\n",
    "        l3 = np.dot(l2_activ,self.weights[1]) + self.bias[1]\n",
    "        pred = self.sigmoid(l3)\n",
    "        error = sum((-y * np.log(pred)) - ((1-y)*np.log(1-pred)))/len(X)\n",
    "        return sum(error)\n",
    "    def backprop(self,X,y): \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.bias]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        size = X.shape[0]\n",
    "        #Vectorised Implementation of Backprop\n",
    "        a_s = [X] #list to store all activation\n",
    "        #print(\"1st\",a_s)\n",
    "        zs = [] #list to store all zs\n",
    "        activation = X\n",
    "        #Forward Propagation to get the error\n",
    "        for w,b in zip(self.weights, self.bias):\n",
    "            z = np.dot(activation,w) + b\n",
    "            zs.append(z)\n",
    "            activation = self.sigmoid(z)\n",
    "            a_s.append(activation)\n",
    "        #Backward Propagation to get the gradient\n",
    "        #2nd Layer\n",
    "        delta = (a_s[-1] -y)*self.sigmoid_deriv(zs[-1]) #Delta will be a 11x10 matrix here\n",
    "        nabla_b[-1] = delta/size\n",
    "        nabla_w[-1] = np.dot(a_s[-2].transpose(),delta)/size\n",
    "        #print(\"2nd Weight\",nabla_w[-1])\n",
    "        #1st Layer - This can actually be done in a more dynamic way to accomodate more layers\n",
    "        delta2 = np.dot(delta, self.weights[-1].transpose()) * self.sigmoid_deriv(zs[-2])\n",
    "        nabla_b[-2] = delta2/size\n",
    "        #print(a_s[-3])\n",
    "        nabla_w[-2] = np.dot(a_s[-3].transpose(), delta2)/size\n",
    "        #print(nabla_w[-2])\n",
    "        #print(\"Bias\",nabla_b)\n",
    "       # print(len(nabla_w))\n",
    "        return(nabla_b,nabla_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Gradient Checking to see if it is actually working\n",
    "X = train.loc[:1,\"X\"]\n",
    "X = np.array([X[i] for i in range(len(X))])\n",
    "y = train.loc[:1,\"y\"]\n",
    "y = np.array([y[i] for i in range(len(y))])\n",
    "jinbe = Network()\n",
    "cb,cw = jinbe.backprop(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [-0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [-0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [-0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [-0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [-0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.19624110e-14, -1.64608701e-14,  3.55710364e-14,\n",
       "          1.19440576e-13,  4.39145740e-16,  1.33453450e-15,\n",
       "          4.89275639e-17,  7.33621106e-14,  1.19016853e-13,\n",
       "          1.30164229e-13],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.44894516e-62, -1.99382032e-62,  4.30853625e-62,\n",
       "          1.44672212e-61,  5.31914594e-64,  1.61645284e-63,\n",
       "          5.92634356e-65,  8.88597422e-62,  1.44158978e-61,\n",
       "          1.57661220e-61],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.53992261e-05, -2.11900979e-05,  4.57906383e-05,\n",
       "          1.53755998e-04,  5.65312843e-07,  1.71794788e-06,\n",
       "          6.29845123e-08,  9.44391338e-05,  1.53210539e-04,\n",
       "          1.67560570e-04],\n",
       "        [ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00]])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:,\"X\"]\n",
    "X = np.array([X[i] for i in range(len(X))])\n",
    "y = train.loc[:,\"y\"]\n",
    "y = np.array([y[i] for i in range(len(y))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 with a cost of  6.666737448012245\n",
      "Epoch 10 with a cost of  4.703170162643325\n",
      "Epoch 20 with a cost of  4.743184052817327\n",
      "Epoch 30 with a cost of  4.817792309224899\n",
      "Epoch 40 with a cost of  4.867706335814968\n",
      "Epoch 50 with a cost of  4.901054568335985\n",
      "Epoch 60 with a cost of  4.922205742795686\n",
      "Epoch 70 with a cost of  4.935952366391651\n",
      "Epoch 80 with a cost of  4.946130121491059\n",
      "Epoch 90 with a cost of  4.949352785876691\n",
      "Epoch 100 with a cost of  4.950552269424309\n",
      "Epoch 110 with a cost of  4.94661184933806\n",
      "Epoch 120 with a cost of  4.9394241551432545\n",
      "Epoch 130 with a cost of  4.933407890953151\n",
      "Epoch 140 with a cost of  4.921018644561162\n",
      "Epoch 150 with a cost of  4.909020077509087\n",
      "Epoch 160 with a cost of  4.898293332468257\n",
      "Epoch 170 with a cost of  4.885052017919108\n",
      "Epoch 180 with a cost of  4.871538645320821\n",
      "Epoch 190 with a cost of  4.857296583813621\n",
      "Epoch 200 with a cost of  4.844530916237493\n",
      "Epoch 210 with a cost of  4.8300359635064\n",
      "Epoch 220 with a cost of  4.8148730089078615\n",
      "Epoch 230 with a cost of  4.800003046561098\n",
      "Epoch 240 with a cost of  4.7867503323581495\n",
      "Epoch 250 with a cost of  4.773144197607035\n",
      "Epoch 260 with a cost of  4.758646342977754\n",
      "Epoch 270 with a cost of  4.742627953044066\n",
      "Epoch 280 with a cost of  4.727069706406226\n",
      "Epoch 290 with a cost of  4.711571457800901\n",
      "Epoch 300 with a cost of  4.6929754616806365\n",
      "Epoch 310 with a cost of  4.674163942907474\n",
      "Epoch 320 with a cost of  4.655641760382351\n",
      "Epoch 330 with a cost of  4.641962618054557\n",
      "Epoch 340 with a cost of  4.627346264163769\n",
      "Epoch 350 with a cost of  4.611374133407759\n",
      "Epoch 360 with a cost of  4.596906529829251\n",
      "Epoch 370 with a cost of  4.582542352108071\n",
      "Epoch 380 with a cost of  4.5712367440396875\n",
      "Epoch 390 with a cost of  4.5559706400221645\n",
      "Epoch 400 with a cost of  4.539742498693305\n",
      "Epoch 410 with a cost of  4.526766210181126\n",
      "Epoch 420 with a cost of  4.510659368488838\n",
      "Epoch 430 with a cost of  4.493805300692775\n",
      "Epoch 440 with a cost of  4.479512520884874\n",
      "Epoch 450 with a cost of  4.4639452170747\n",
      "Epoch 460 with a cost of  4.451018562404887\n",
      "Epoch 470 with a cost of  4.432912224054714\n",
      "Epoch 480 with a cost of  4.416022122314716\n",
      "Epoch 490 with a cost of  4.400025221569573\n",
      "Epoch 500 with a cost of  4.386125261731795\n",
      "Epoch 510 with a cost of  4.370628450347786\n",
      "Epoch 520 with a cost of  4.353669290881672\n",
      "Epoch 530 with a cost of  4.337313171512798\n",
      "Epoch 540 with a cost of  4.321543833654159\n",
      "Epoch 550 with a cost of  4.305723573032953\n",
      "Epoch 560 with a cost of  4.286438729962044\n",
      "Epoch 570 with a cost of  4.265776593316513\n",
      "Epoch 580 with a cost of  4.250514669194882\n",
      "Epoch 590 with a cost of  4.230709483472102\n",
      "Epoch 600 with a cost of  4.213660800985028\n",
      "Epoch 610 with a cost of  4.195898704487152\n",
      "Epoch 620 with a cost of  4.1778558221227495\n",
      "Epoch 630 with a cost of  4.162105183903548\n",
      "Epoch 640 with a cost of  4.145103629324133\n",
      "Epoch 650 with a cost of  4.127761942686296\n",
      "Epoch 660 with a cost of  4.110245782395237\n",
      "Epoch 670 with a cost of  4.0910963738117605\n",
      "Epoch 680 with a cost of  4.0734355847121915\n",
      "Epoch 690 with a cost of  4.0571578865760785\n",
      "Epoch 700 with a cost of  4.041124306188308\n",
      "Epoch 710 with a cost of  4.02606679510182\n",
      "Epoch 720 with a cost of  4.007616921837603\n",
      "Epoch 730 with a cost of  3.992533393418205\n",
      "Epoch 740 with a cost of  3.977337112712969\n",
      "Epoch 750 with a cost of  3.960598693642985\n",
      "Epoch 760 with a cost of  3.9434056206516583\n",
      "Epoch 770 with a cost of  3.928046341902026\n",
      "Epoch 780 with a cost of  3.9142900960023814\n",
      "Epoch 790 with a cost of  3.8987521116058224\n",
      "Epoch 800 with a cost of  3.883249380511636\n",
      "Epoch 810 with a cost of  3.8686661778264875\n",
      "Epoch 820 with a cost of  3.8502117783038363\n",
      "Epoch 830 with a cost of  3.834036807408334\n",
      "Epoch 840 with a cost of  3.8179058335996237\n",
      "Epoch 850 with a cost of  3.7990211569170973\n",
      "Epoch 860 with a cost of  3.7857097681848506\n",
      "Epoch 870 with a cost of  3.770557284554065\n",
      "Epoch 880 with a cost of  3.7539271893210575\n",
      "Epoch 890 with a cost of  3.7362375855415886\n",
      "Epoch 900 with a cost of  3.7218949117128486\n",
      "Epoch 910 with a cost of  3.7065490349404175\n",
      "Epoch 920 with a cost of  3.6878778378865125\n",
      "Epoch 930 with a cost of  3.6712852236500795\n",
      "Epoch 940 with a cost of  3.655415271890785\n",
      "Epoch 950 with a cost of  3.639443391544188\n",
      "Epoch 960 with a cost of  3.6239330979082593\n",
      "Epoch 970 with a cost of  3.6071967741066104\n",
      "Epoch 980 with a cost of  3.590269027209799\n",
      "Epoch 990 with a cost of  3.575294918012364\n",
      "Epoch 1000 with a cost of  3.5563042096999835\n",
      "Epoch 1010 with a cost of  3.5374595962765394\n",
      "Epoch 1020 with a cost of  3.5219686193119015\n",
      "Epoch 1030 with a cost of  3.5028727631104783\n",
      "Epoch 1040 with a cost of  3.485624458436395\n",
      "Epoch 1050 with a cost of  3.46646310204512\n",
      "Epoch 1060 with a cost of  3.4510136515248284\n",
      "Epoch 1070 with a cost of  3.4291184569261963\n",
      "Epoch 1080 with a cost of  3.4139988989737904\n",
      "Epoch 1090 with a cost of  3.392492869959169\n",
      "Epoch 1100 with a cost of  3.3741231633351347\n",
      "Epoch 1110 with a cost of  3.355635029355472\n",
      "Epoch 1120 with a cost of  3.337587304516379\n",
      "Epoch 1130 with a cost of  3.320408939639387\n",
      "Epoch 1140 with a cost of  3.3069004485394924\n",
      "Epoch 1150 with a cost of  3.2862133341368893\n",
      "Epoch 1160 with a cost of  3.268231248252421\n",
      "Epoch 1170 with a cost of  3.249319093751552\n",
      "Epoch 1180 with a cost of  3.234854926129951\n",
      "Epoch 1190 with a cost of  3.21874772396389\n",
      "Epoch 1200 with a cost of  3.205661809356773\n",
      "Epoch 1210 with a cost of  3.1842725807565584\n",
      "Epoch 1220 with a cost of  3.1685078640055537\n",
      "Epoch 1230 with a cost of  3.152298073513116\n",
      "Epoch 1240 with a cost of  3.1344048346869626\n",
      "Epoch 1250 with a cost of  3.1166504337637613\n",
      "Epoch 1260 with a cost of  3.100138994923278\n",
      "Epoch 1270 with a cost of  3.083281548839328\n",
      "Epoch 1280 with a cost of  3.063835248438563\n",
      "Epoch 1290 with a cost of  3.0498379059173706\n",
      "Epoch 1300 with a cost of  3.029437703705952\n",
      "Epoch 1310 with a cost of  3.011782987960359\n",
      "Epoch 1320 with a cost of  2.997090437037528\n",
      "Epoch 1330 with a cost of  2.9828292909587937\n",
      "Epoch 1340 with a cost of  2.965676904296584\n",
      "Epoch 1350 with a cost of  2.950232482291579\n",
      "Epoch 1360 with a cost of  2.9323750794808126\n",
      "Epoch 1370 with a cost of  2.9150685759593475\n",
      "Epoch 1380 with a cost of  2.90162009547567\n",
      "Epoch 1390 with a cost of  2.8851632960126863\n",
      "Epoch 1400 with a cost of  2.869736506668031\n",
      "Epoch 1410 with a cost of  2.854336061498036\n",
      "Epoch 1420 with a cost of  2.8386676941831253\n",
      "Epoch 1430 with a cost of  2.8217852083686816\n",
      "Epoch 1440 with a cost of  2.803947036349341\n",
      "Epoch 1450 with a cost of  2.7887384023244297\n",
      "Epoch 1460 with a cost of  2.7753128578049457\n",
      "Epoch 1470 with a cost of  2.7593457598141926\n",
      "Epoch 1480 with a cost of  2.7435369570956856\n",
      "Epoch 1490 with a cost of  2.72988920897421\n",
      "Epoch 1500 with a cost of  2.7136823320926955\n",
      "Epoch 1510 with a cost of  2.697207866219421\n",
      "Epoch 1520 with a cost of  2.6821939214395503\n",
      "Epoch 1530 with a cost of  2.6670335428330203\n",
      "Epoch 1540 with a cost of  2.6521273278411632\n",
      "Epoch 1550 with a cost of  2.636970380432202\n",
      "Epoch 1560 with a cost of  2.6232610980022772\n",
      "Epoch 1570 with a cost of  2.6083667410960567\n",
      "Epoch 1580 with a cost of  2.5933564349384493\n",
      "Epoch 1590 with a cost of  2.5798799064700377\n",
      "Epoch 1600 with a cost of  2.5646240302541967\n",
      "Epoch 1610 with a cost of  2.5498316773732874\n",
      "Epoch 1620 with a cost of  2.536599914274678\n",
      "Epoch 1630 with a cost of  2.524568232624596\n",
      "Epoch 1640 with a cost of  2.510100343081227\n",
      "Epoch 1650 with a cost of  2.4991550625524397\n",
      "Epoch 1660 with a cost of  2.4858013678570368\n",
      "Epoch 1670 with a cost of  2.474104464655132\n",
      "Epoch 1680 with a cost of  2.4616038414653394\n",
      "Epoch 1690 with a cost of  2.451263179315099\n",
      "Epoch 1700 with a cost of  2.437373454539197\n",
      "Epoch 1710 with a cost of  2.426049448689293\n",
      "Epoch 1720 with a cost of  2.4110631650589487\n",
      "Epoch 1730 with a cost of  2.40090422657201\n",
      "Epoch 1740 with a cost of  2.3878856588866415\n",
      "Epoch 1750 with a cost of  2.37845633501922\n",
      "Epoch 1760 with a cost of  2.3673475275414075\n",
      "Epoch 1770 with a cost of  2.35601675358663\n",
      "Epoch 1780 with a cost of  2.3453774471344566\n",
      "Epoch 1790 with a cost of  2.3357952332379432\n",
      "Epoch 1800 with a cost of  2.3252602260217192\n",
      "Epoch 1810 with a cost of  2.3158599484099778\n",
      "Epoch 1820 with a cost of  2.3067201417863346\n",
      "Epoch 1830 with a cost of  2.298563032219695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1840 with a cost of  2.288915703551321\n",
      "Epoch 1850 with a cost of  2.2810662746091466\n",
      "Epoch 1860 with a cost of  2.2735808272087024\n",
      "Epoch 1870 with a cost of  2.2627041715570986\n",
      "Epoch 1880 with a cost of  2.25339452255548\n",
      "Epoch 1890 with a cost of  2.242752572271917\n",
      "Epoch 1900 with a cost of  2.230108998197906\n",
      "Epoch 1910 with a cost of  2.221807429229676\n",
      "Epoch 1920 with a cost of  2.212563085776742\n",
      "Epoch 1930 with a cost of  2.204550533318728\n",
      "Epoch 1940 with a cost of  2.196450340835128\n",
      "Epoch 1950 with a cost of  2.188194578640937\n",
      "Epoch 1960 with a cost of  2.180258297407451\n",
      "Epoch 1970 with a cost of  2.1701319191446213\n",
      "Epoch 1980 with a cost of  2.163301636557336\n",
      "Epoch 1990 with a cost of  2.154829205244453\n"
     ]
    }
   ],
   "source": [
    "jinbe = Network(epochs = 2000,learning_rate = 1)\n",
    "jinbe.learn(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()\n",
    "#Transform the data such that there are only 2 columns, 1 being X which is a 28*28 matrix and y which is the label\n",
    "cols = ['pixel'+str(i) for i in range(784)]\n",
    "test['X'] = test[cols].values.tolist()\n",
    "test.drop(cols,inplace = True,axis = 1)\n",
    " # Convert y into a format where is a vector where it is 1 for the correct number and 0 elsewhere\n",
    "test_X =  test.loc[:,\"X\"]\n",
    "test_X = np.array([test_X[i] for i in range(len(test_X))])\n",
    "predictions = jinbe.predict(test_X)\n",
    "labels = [i for i in range(1,len(predictions)+1)]\n",
    "hi = pd.DataFrame(np.array([labels,predictions]).transpose())\n",
    "hi.columns = (\"ImageId\",\"Label\")\n",
    "hi.set_index(\"ImageId\",inplace = True)\n",
    "hi.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "5            1\n",
       "0            2\n",
       "5            3\n",
       "7            4\n",
       "2            5\n",
       "...        ...\n",
       "3        27996\n",
       "7        27997\n",
       "6        27998\n",
       "9        27999\n",
       "5        28000\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  4\n",
       "1  2  0\n",
       "2  3  2\n",
       "3  4  4\n",
       "4  5  4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "predictions2 = jinbe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       X  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "41995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    y  \n",
       "0      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "4      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                               ...  \n",
       "41995  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "41996  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "41997  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "41998  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "41999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'get_indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c6426b31bd22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         return _list_of_series_to_arrays(\n\u001b[1;32m--> 471\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m         )\n\u001b[0;32m    473\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_of_series_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'get_indexer'"
     ]
    }
   ],
   "source": [
    "initial = pd.read_csv(\"train.csv\")\n",
    "ans = initial[\"label\"]\n",
    "hi = pd.DataFrame([ans,predictions2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = pd.Series(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = pd.DataFrame([ans,predictions2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41990</th>\n",
       "      <th>41991</th>\n",
       "      <th>41992</th>\n",
       "      <th>41993</th>\n",
       "      <th>41994</th>\n",
       "      <th>41995</th>\n",
       "      <th>41996</th>\n",
       "      <th>41997</th>\n",
       "      <th>41998</th>\n",
       "      <th>41999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed 0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5      6      7      8      \\\n",
       "label          1      0      1      4      0      0      7      3      5   \n",
       "Unnamed 0      3      5      4      5      5      5      1      7      7   \n",
       "\n",
       "           9      ...  41990  41991  41992  41993  41994  41995  41996  41997  \\\n",
       "label          3  ...      3      1      9      6      4      0      1      7   \n",
       "Unnamed 0      3  ...      0      4      3      1      8      8      4      5   \n",
       "\n",
       "           41998  41999  \n",
       "label          6      9  \n",
       "Unnamed 0      1      4  \n",
       "\n",
       "[2 rows x 42000 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
